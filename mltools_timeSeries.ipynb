{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series tools package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.io import output_file, output_notebook, show\n",
    "import warnings\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/walmart_stock.csv\", index_col=\"Date\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open = data['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.plottingTool.mltools_plot import time_series_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6)\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.timeSeriesTools import imputeTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminiamo una buona \"fetta\" di dati e vediamo come gestire un serie temporali con diversi \"buchi\", di dimensione variabile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#togliamo una \"fetta\" di dati\n",
    "partial_df = open[~open.index.isin(pd.date_range(start = '2014-01-09', end='2014-04-12', freq='D'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ricostruire il dataset completo, utilizziamo la funzione di pandas per ricostruire il range di date, che saranno poi utilizzate come indici per il nuovo dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = imputeTS.ReconstructTS(data=partial_df, start = open.index[0], end = open.index[-1], freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = complete_data, fig=f2, alpha = 0.6)\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È anche possibile ricostruire la serie utilizzando una interpolazione lineare. Questo è possibile impostante il flag \"interpolate\" uguale a True e, inoltre, scegliamo anche di limitare i NaN consecutivi, per cui è accettabile l'interpolazione, a 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = imputeTS.ReconstructTS(data=partial_df, start = open.index[0], end = open.index[-1], freq='D', \n",
    "                                       interpolate=True, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = complete_data, fig=f2, alpha = 0.6)\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing by resample the time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.timeSeriesTools import smoothingFilters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_5day = smoothingFilters.AggregateData(method=\"mean\", interval=\"5D\")\n",
    "max_5day = smoothingFilters.AggregateData(method=\"max\", interval=\"5D\")\n",
    "min_5day = smoothingFilters.AggregateData(method=\"min\", interval=\"5D\")\n",
    "perc_5day = smoothingFilters.AggregateData(method=\"percentile\", interval=\"5D\", percentile=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_mean_5day = mean_5day.fit(open)\n",
    "open_max_5day = max_5day.fit(open)\n",
    "open_min_5day = min_5day.fit(open)\n",
    "open_perc_5day = perc_5day.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6)\n",
    "f2 = time_series_plot.plot_time_series(data = open_mean_5day, fig=f2, color = \"red\", linestyle=\"dashed\", legend=\"mean\")\n",
    "f2 = time_series_plot.plot_time_series(data = open_max_5day, fig=f2, color = \"green\", linestyle=\"solid\", legend = \"max\")\n",
    "f2 = time_series_plot.plot_time_series(data = open_min_5day, fig=f2, color = \"orange\", linestyle=\"solid\", legend = \"min\")\n",
    "f2 = time_series_plot.plot_time_series(data = open_perc_5day, fig=f2, color = \"lightblue\", linestyle=\"dashed\", legend = \"percentile\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple moving average or an exponential moving average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ma = smoothingFilters.MovingAverage(method=\"simple\", window_size=5)\n",
    "exp_ma = smoothingFilters.MovingAverage(method=\"exponential\", window_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ma_data = simple_ma.fit(open)\n",
    "exp_ma_data = exp_ma.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6, color = \"green\", linewidth=2)\n",
    "f2 = time_series_plot.plot_time_series(data = simple_ma_data, fig=f2, alpha = 0.6, color = \"blue\", legend = \"simple MA\")\n",
    "f2 = time_series_plot.plot_time_series(data = exp_ma_data, fig=f2, alpha = 0.6, color = \"red\", legend = \"exponential MA\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savitzky Golay filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savgol = smoothingFilters.SavGol_smoothing(polyorder=1, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savgol_data = savgol.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6, color = \"green\", linewidth=2)\n",
    "f2 = time_series_plot.plot_time_series(data = savgol_data, fig=f2, alpha = 0.6, color = \"blue\", legend = \"Sav-Gol Filter\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.timeSeriesTools import trendAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = trendAnalysis.TrendAnalysis(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_trend = linear_regression.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6, color = \"blue\", linewidth=1)\n",
    "f2 = time_series_plot.plot_time_series(data = linear_trend, linewidth=3, fig=f2, alpha = 0.6, color = \"red\", legend = \"Linear trend\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowess Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess_regression = trendAnalysis.TrendAnalysis(method=\"lowess\", smooth=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess_trend = lowess_regression.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6, color = \"blue\", linewidth=1)\n",
    "f2 = time_series_plot.plot_time_series(data = lowess_trend, linewidth=2, fig=f2, alpha = 0.6, color = \"red\", legend = \"Lowess trend\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanding_mean = trendAnalysis.TrendAnalysis(method=\"expanding_mean\", period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanding_trend = expanding_mean.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6, color = \"blue\", linewidth=1)\n",
    "f2 = time_series_plot.plot_time_series(data = expanding_trend, linewidth=2, fig=f2, alpha = 0.6, color = \"red\", legend = \"Lowess trend\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bollinger bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bollinger_bands = trendAnalysis.TrendAnalysis(method=\"bollinger_bands\", windows_size=20, delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_band, lower_band = bollinger_bands.fit(open) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.6, color = \"blue\", linewidth=1)\n",
    "f2 = time_series_plot.plot_time_series(data = upper_band, linewidth=1, fig=f2, alpha = 0.6, color = \"red\", legend = \"Upper band\")\n",
    "f2 = time_series_plot.plot_time_series(data = lower_band, linewidth=1, fig=f2, alpha = 0.6, color = \"green\", legend = \"Lower band\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.timeSeriesTools import ets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets.ETS_decomposition.methods_avaible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_passanger = pd.read_csv(\"data/airline_passengers.csv\", index_col=\"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_passanger.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_passanger.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_passanger.index = airline_passanger.index.astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = airline_passanger, fig=f2, alpha = 0.6)\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hodrick-Prescott filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_filter = ets.ETS_decomposition(method=\"hp_filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle, trend = hp_filter.fit(airline_passanger[\"Thousands of Passengers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = airline_passanger[\"Thousands of Passengers\"], fig=f2, alpha = 0.6, color = \"blue\", linewidth=1)\n",
    "f2 = time_series_plot.plot_time_series(data = trend, linewidth=2, fig=f2, alpha = 0.6, color = \"red\", legend = \"Trend\")\n",
    "f2 = time_series_plot.plot_time_series(data = cycle, linewidth=2, fig=f2, alpha = 0.6, color = \"orange\", legend = \"Cycle\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSA Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_L5 = ets.ETS_decomposition(method=\"ssa\", L = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_ssa_L5 = ssa_L5.fit(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_comp = F_ssa_L5.components_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_ssa_L5.plot_wcorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = F_ssa_L5.reconstruct(0)\n",
    "F1 = F_ssa_L5.reconstruct([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = open, fig=f2, alpha = 0.4, color = \"blue\", linewidth=1.2, legend = \"Original data\")\n",
    "f2 = time_series_plot.plot_time_series(data = F0, linewidth=1, fig=f2, alpha = 0.8, color = \"red\", legend = \"F0\")\n",
    "f2 = time_series_plot.plot_time_series(data = F1, linewidth=1, fig=f2, alpha = 0.8, color = \"green\", legend = \"F1\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_L20 = ets.ETS_decomposition(method=\"ssa\", L=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_ssa_L20 = ssa_L20.fit(airline_passanger[\"Thousands of Passengers\"])\n",
    "ssa_comp = F_ssa_L20.components_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_ssa_L20.plot_wcorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = F_ssa_L20.reconstruct(0)\n",
    "F1 = F_ssa_L20.reconstruct([1,2])\n",
    "F2 = F_ssa_L20.reconstruct([3,4])\n",
    "F3 = F_ssa_L20.reconstruct(slice(5,12))\n",
    "F4 = F_ssa_L20.reconstruct(slice(12,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = F0, linewidth=1, fig=f2, alpha = 0.8, color = \"blue\", legend = \"F0\")\n",
    "f2 = time_series_plot.plot_time_series(data = F1, linewidth=1, fig=f2, alpha = 0.8, color = \"green\", legend = \"F1\")\n",
    "f2 = time_series_plot.plot_time_series(data = F2, linewidth=1, fig=f2, alpha = 0.8, color = \"red\", legend = \"F2\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_ssa_L20_main_components = F_ssa_L20.get_main_components(corr_threshold=0.45,adjust=0)\n",
    "F_ssa_L20_main_components.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = F_ssa_L20_main_components.iloc[:,0]\n",
    "F1 = F_ssa_L20_main_components.iloc[:,1]\n",
    "F2 = F_ssa_L20_main_components.iloc[:,2]\n",
    "noise = F_ssa_L20_main_components.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = F0, linewidth=1, fig=f2, alpha = 0.8, color = \"blue\", legend = \"F0\")\n",
    "f2 = time_series_plot.plot_time_series(data = F1, linewidth=1, fig=f2, alpha = 0.8, color = \"green\", legend = \"F1\")\n",
    "f2 = time_series_plot.plot_time_series(data = F2, linewidth=1, fig=f2, alpha = 0.8, color = \"red\", legend = \"F2\")\n",
    "f2 = time_series_plot.plot_time_series(data = noise, linewidth=1, fig=f2, alpha = 0.8, color = \"purple\", legend = \"Noise\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F_ssa_L20.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = ets.ETS_decomposition(method=\"seasonal_decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = airline_passanger[\"Thousands of Passengers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend, seasonal, residual = sd.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f1 = figure(x_axis_type=\"datetime\")\n",
    "f1 = time_series_plot.plot_time_series(data = data, title='Airline Passengers',\n",
    "                                       linewidth=1, fig=f1, alpha = 0.8)\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = trend, title='Airline Passengers - Trend',\n",
    "                                       linewidth=1, fig=f2, alpha = 0.8)\n",
    "\n",
    "f3 = figure(x_axis_type=\"datetime\")\n",
    "f3 = time_series_plot.plot_time_series(data = seasonal, title='Airline Passengers - Stagionalità',\n",
    "                                       linewidth=1, fig=f3, alpha = 0.8)\n",
    "\n",
    "f4 = figure(x_axis_type=\"datetime\")\n",
    "f4 = time_series_plot.plot_time_series(data = residual, title='Airline Passengers - Residui',\n",
    "                                       linewidth=1, fig=f4, alpha = 0.8)\n",
    "\n",
    "f = gridplot([f1], [f2], [f3], [f4])\n",
    "show(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change point analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.timeSeriesTools import CPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possiamo vedere quali metodi usare con l'attributo 'methods_av'\n",
    "CPA.methods_av"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il pacchetto utilizza delle librerie R che sono state incluse all'interno di un wrapper Python. Per questo motivo si consiglia, prima di utilizzare le funzioni messe a disposizione, di utilizzare la funzione get_libraries per identificare le librerie R necessarie. I pacchetti che non vengono individuati possono essere installati direttamente attraverso le caselle di input visualizzate e seguendo la procedura guidata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POSSIAMO INSTALLARE LE LIBRERIE NECESSARIE CON LA FUNZIONE \"get_libraries\"\n",
    "#NB: Prophet richiede molto tempo per l'installazione\n",
    "#CPA.get_libraries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/DJI.csv\", index_col='Date', parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ricerca dei changepoints viene fatta istanziando un oggetto CPA e scegliendo il metodo che si vuole utilizzare. Richiamando il metodo _fit()_ si effettua la ricerca dei cp e il risultato è un dizionario che ha come chiave il nome del modello e come valore la lista degli indici dove sono stati trovati i changepoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Changepoints per la media**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbs = CPA(method = 'wbs') \n",
    "cp_wbs = wbs.fit(data = df['Close'], model_param={'n_checkpoints':5,\n",
    "                                                  'penalty_wbs':'SSIC',\n",
    "                                                  'n_intervals':400,\n",
    "                                                  'th_wbs':0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amoc = CPA(method='AMOC')\n",
    "cp_amoc = amoc.fit(data = df['Close'], model_param={'n_checkpoints':5,\n",
    "                                                    'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binseg = CPA(method='BinSeg')\n",
    "cp_binseg = binseg.fit(data = df['Close'], model_param={'n_checkpoints':5,\n",
    "                                                    'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segneigh = CPA(method='SegNeigh')\n",
    "cp_segneigh = segneigh.fit(data = df['Close'], model_param={'n_checkpoints':5,\n",
    "                                                    'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time bcp = CPA(method='bcp')\n",
    "cp_bcp = bcp.fit(data = df['Close'], model_param={'n_checkpoints':5,\n",
    "                                                    'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet = CPA(method='PROPHET')\n",
    "cp_prophet = prophet.fit(data = df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ecp = CPA(method='ecp')\n",
    "cp_ecp = ecp.fit(data = df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPA.plot_changepoints(data = df['Close'],\n",
    "                      cp_list=[cp_wbs, cp_amoc, cp_binseg,\n",
    "                               cp_segneigh, cp_bcp, cp_ecp],\n",
    "                      colors='#123456')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Changepoints per la varianza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amoc = CPA(method='AMOC')\n",
    "#NB: AMOC ritorna sempre ad un unico cp\n",
    "cp_amoc = amoc.fit(data = df['Close'],\n",
    "                   compute_mean = False,\n",
    "                   model_param={'n_checkpoints':5,\n",
    "                                'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binseg = CPA(method='BinSeg')\n",
    "cp_binseg = binseg.fit(data = df['Close'],\n",
    "                       compute_mean = False,\n",
    "                       model_param={'n_checkpoints':5,\n",
    "                                    'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segneigh = CPA(method='SegNeigh')\n",
    "cp_segneigh = segneigh.fit(data = df['Close'],\n",
    "                           compute_mean=False,\n",
    "                           model_param={'n_checkpoints':5,\n",
    "                                        'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pelt = CPA(method='PELT')\n",
    "cp_pelt = pelt.fit(data = df['Close'],\n",
    "                   compute_mean=False,\n",
    "                   model_param={'n_checkpoints':5,\n",
    "                                'penalty_bs':'AIC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPA.plot_changepoints(data = df['Close'], cp_list=[cp_amoc, cp_binseg, cp_segneigh, cp_pelt], colors='#123456')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.timeSeriesTools import forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series log transformation \n",
    "data = pd.read_csv(\"data/airline_passengers.csv\", index_col=\"Month\")\n",
    "data.dropna(inplace=True)\n",
    "data.index = data.index.astype(\"datetime64[ns]\")\n",
    "data.columns = ['Passengers']\n",
    "data.index.name = 'Months'\n",
    "ts_log = np.log(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = data[\"Passengers\"], fig=f2, alpha = 0.6,\n",
    "                                       color = \"blue\", linewidth=1)\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = ts_log[\"Passengers\"], linewidth=1, fig=f2, alpha = 0.6, color = \"red\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifica di stazionarietà della Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(ts_log[\"Passengers\"])\n",
    "\n",
    "print('Original data')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('  %s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con l'attributo di classe models_available è possibile richiamare la lista dei modelli\n",
    "# implementati dalla classe forecasting\n",
    "\n",
    "forecasting.ForecastingTS.models_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo _plot_diagram_ permette di eseguire una prima ispezione, plottando, oltre alla time series, la distribuzione dei suoi valori e i diagrammi di Autocorrelazione totale e parziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting.plot_diagram(ts_log['Passengers'], bins=10,lags=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **ARIMA**\n",
    "\n",
    "Come prima cosa vediamo come fittare un modello SARIMAX sui dati a disposizione. Per fare questo, si parte instanziando il modello come istanza della classe ForecastingTS. Con la stessa classe di metodi è possibile ottenere anche un normale modello ARIMA: in questo caso è necessario settare ulteriori parametri passandoli attraverso il dizionario model_param. Per ottenere un modello arima è sufficiente settare la variabile \"exog\" come None (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Arima model\n",
    "arima = forecasting.ForecastingTS(model='SARIMAX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fit del metodo è identico a quanto visto in precedenza: è sufficiente passare una series il cui indice è la data dell'osservazione. Oltre questo valore, è possibile specificare, nel dizionario fit_params, altri parametri che verranno utilizzati dalla funzione che effettua il fitting del modello  come \"s\" (periodicità) e \"max_value\" (limite massimo in cui far variare i parametri durante il gridsearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time res_arima = arima.fit(ts_log['Passengers'], gridsearch=True, fit_params={'s': 12, 'max_value': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arima = arima.predict(start_date= '1960-12', end_date='1965-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **HWES (Holt-Winter's Exponential Smoothing)**\n",
    "\n",
    "Nel secondo caso utilizziamo lo smoothing esponenziale per effettuare le nostre previsioni. Con questo metodo è possibile analizzare serie univariate con componenti di trend/stagionalità. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwse = forecasting.ForecastingTS(model='HWES', model_params={'seasonal_periods': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time res_hwes = hwse.fit(ts_log['Passengers'], gridsearch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hwes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hwes = hwse.predict(start_date= '1960-12-01', end_date='1965-12-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Facebook Prophet**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting prophet model \n",
    "prophet = forecasting.ForecastingTS(model='Prophet')\n",
    "#per il modello di crescita logistica (limitata)\n",
    "#prophet = forecasting.ForecastingTS(model='Prophet', gridsearch=True, model_params={'growth': 'logistic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = pd.Series(np.repeat(ts_log['Passengers'].quantile(), repeats=len(ts_log['Passengers'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time res_prophet = prophet.fit(ts_log['Passengers'], gridsearch=True)\n",
    "#per il modello di crescita logistica (limitata)\n",
    "#res_prophet = prophet.fit(ts_log['Passengers'], fit_params = {'cap':cap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prophet = prophet.predict(start_date= '1960-12-01',\n",
    "                               end_date='1965-12-01',\n",
    "                               pred_params={'freq': 'MS'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi dei residui sul training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting.plot_diagnostics(hwse.residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confronto delle previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "f2 = figure(x_axis_type=\"datetime\")\n",
    "f2 = time_series_plot.plot_time_series(data = ts_log, linewidth=1, fig=f2,\n",
    "                                       alpha = 0.8, color = \"blue\", legend = \"Passengers\")\n",
    "f2 = time_series_plot.plot_time_series(data = pred_arima.predicted_mean, linewidth=1, fig=f2,\n",
    "                                       alpha = 0.8, color = \"green\", legend = \"SARIMAX Forecastings\")\n",
    "f2 = time_series_plot.plot_time_series(data = pred_hwes, linewidth=1, fig=f2,\n",
    "                                       alpha = 0.8, color = \"red\", legend = \"HWES Forecastings\")\n",
    "f2 = time_series_plot.plot_time_series(data = pred_prophet, linewidth=1, fig=f2,\n",
    "                                       alpha = 0.8, color = \"orange\", legend = \"PROPHET Forecastings\")\n",
    "show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
