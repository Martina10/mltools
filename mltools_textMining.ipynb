{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizzo del pacchetto mltools per il preprocessing e l'analisi dei testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importiamo il dataset contenente i testi che intediamo analizzare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/20newsgroup_body.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo la presenza di dati mancanti, in questo caso documenti vuoti senza testo: notiamo che ne sono presenti alcuni nel nostro dataset, per questo motivo provvediamo ad eliminarli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo ora come utilizzare il pacchetto mltools per l'analisi dei testi. Tramite l'import del modulo textMining è possibile utilizzare alcune classi per il preprocessing dei testi, al fine di rendere questi in forma eligibile per i modelli di classificazione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} classi trovate\\nClassi:\\n{}'.format(len(df['class'].unique()), df['class'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining import TextPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istanziamo la classe text_preprocessing: in questo caso impostiamo il flag per effettuare la lemmatization uguale a False (i tempi computazionali diventano lunghi se True); il metodo che andremo poi a fittare sui dati andrà in questo caso ad effettuare una rimozione dei caratteri speciali (conserva solo le parole) e delle stopwords presenti nel testo. L'output sarà un pandas DataFrame uguale all'originale, ma con l'aggiunta di una colonna contenente i token estratti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessing(lemmatization = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto possiamo estrarre i token prensenti nei documenti, passando al metodo *fit* il dataframe contenente l'estratto dei testi e il nome del campo che intendiamo processare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tp.fit(df, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization del testo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora a trasformare i token in una matrice di feature che potrà essere poi utilizzata dai modelli predittivi per la classificazione dei testi. In questo caso andiamo ad utilizzare come metrica per rappresentare le parole, il tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suddivisione training set / test set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(output[[\"tokens\", \"filename\"]], output[\"class\"], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora al metodo per vettorizzare le parole le pandas Series contenti i token estratti in precedenza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining.textProcessing import VectorizeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_toVect = VectorizeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, vectorizer = token_toVect.fit(X_train[\"tokens\"], X_test[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione dei topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 1000\n",
    "token_toVect = VectorizeData(method='count')\n",
    "X_train_count, X_test_count, count_vectorizer = token_toVect.fit(X_train[\"tokens\"],\n",
    "                                                        X_test[\"tokens\"])\n",
    "count_feature_names = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus from a list of texts\n",
    "texts = list(X_train['tokens'])\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the corpus.\n",
    "lda = LdaModel(corpus, num_topics=20, id2word = dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics \n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "no_topics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "lda = LDA(n_components=no_topics, max_iter=5,\n",
    "          learning_method='online', random_state=123)\n",
    "lda_output = lda.fit_transform(X_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic_model in enumerate(model.components_):\n",
    "        print (\"\\nTopic #%d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                         for i in topic_model.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "display_topics(lda, count_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello con una alta log-likelihood e bassa perplexity [exp(-1. * log-likelihood per word)] è considerato un buon modello. Controlliamo il nostro modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda.score(X_train_count))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda.perplexity(X_train_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettuiamo una GridSearch sui parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo una nuova istanza con il nuovo modello\n",
    "lda = LDA(learning_decay= 0.7, learning_method='online',\n",
    "          n_components= 10,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topics for some given samples:\n",
    "lda_output = lda.fit_transform(X_train_count)\n",
    "lda_output = lda.fit_transform(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topic_dataframe(model, matrix, limit_row):\n",
    "    # column names\n",
    "    topicnames = [\"Topic\" + str(i) for i in range(model.n_components)]\n",
    "\n",
    "    # index names\n",
    "    docnames = [\"Doc\" + str(i) for i in range(matrix.shape[0])]\n",
    "\n",
    "    # Make the pandas dataframe\n",
    "    df_document_topic = pd.DataFrame(np.round(matrix, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "    # Get dominant topic for each document\n",
    "    dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "    df_document_topic['dominant_topic'] = dominant_topic\n",
    "    df_document_topics = df_document_topic.head(limit_row).style.applymap(color_green).applymap(make_bold)\n",
    "    return df_document_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_topic_dataframe(lda, X_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "vis = pyLDAvis.sklearn.prepare(lda, X_train_count, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining.word2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = load_model(\"GoogleNews-vectors-negative300.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_word2vec_embeddings(word2vec_model, output, \"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto, utilizziamo il modello evaluateModels per effettuare una CrossValidation e identificare i modelli migliori: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.evaluateModels import CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidation(models=[\"MultinomialNB\", \"LogisticRegression\"], \n",
    "                     scores = [\"accuracy\", \"f1_multiclass\", \"precision_multiclass\", \"recall_multiclass\"],\n",
    "                     params_file = \"./param_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_models_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_scores_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, model = cv.fit_cv(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "\n",
    "nb_clf = model['MultinomialNB']\n",
    "nb_clf = nb_clf.fit(X_train_tfidf, y_train) \n",
    "y_predicted = nb_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuratezza di MultinomialNB su test set:\", accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi dell'importanza delle parole nella classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_clf = model['LogisticRegression']\n",
    "lgr_clf = lgr_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = get_most_important_features(vectorizer, lgr_clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_important_words(importance, lgr_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi della frequenza della parole nei documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining.featuresImportance import plot_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_freq(output, target=\"class\", col=\"tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBC NEWS SUMMARIZATION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima cosa, importiamo le librerie necessarie e creiamo il dataset per l'analisi, leggendo i file contenenti gli articoli della BBC relativi all'area di business e i riassunti corrispondenti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_news = \"./data/BBC_Business_News/business_news\"\n",
    "path_summary = \"./data/BBC_Business_News/business_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(path, column_name):\n",
    "    dataset = pd.DataFrame()\n",
    "    filename_list = os.listdir(path)\n",
    "    for filename in filename_list:\n",
    "        with codecs.open(\"{}/{}\".format(path, filename), \"r\", encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.readlines()\n",
    "            clean_text = [re.sub(r'(\\n)', '', line) for line in text]\n",
    "            complete_text = \" \".join(clean_text)\n",
    "            df = np.array(complete_text).reshape(1,1)\n",
    "        dataset = pd.concat([dataset, pd.DataFrame(df)])\n",
    "        \n",
    "    dataset.columns = [column_name]\n",
    "    dataset.index = np.arange(len(dataset))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_news = create_df(path_news, 'article')\n",
    "dataset_summaries = create_df(path_summary, 'reference_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_finale = pd.concat([dataset_news, dataset_summaries], axis = 1)\n",
    "dataset_finale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_finale = dataset_finale[dataset_finale['article'].apply(len) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_news['article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_finale.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'obiettivo della 'Summarization' è creare un riassunto quanto più rappresentativo possibile dell'intero documento.\n",
    "\n",
    "In particolare, la classe implementata utilizza i cosiddetti metodi 'extraction-based', che lavorano selezionando un sottoinsieme delle frasi più importanti esistenti nel testo originario per comporre il riassunto. \n",
    "\n",
    "Gli algoritmi che possono essere testati, restituiti dal metodo 'getInfo_models', sono i seguenti:\n",
    "- TextRank (gensim e sumy);\n",
    "- LexRank (sumy);\n",
    "- Lsa (sumy);\n",
    "- Luhn (sumy). \n",
    "\n",
    "Inoltre, settando il parametro 'keywords' uguale a True, la classe estrae le keywords dal testo in input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima cosa prima di procedere con la generazione dei riassunti, è necessario filtrare il campo del testo per eliminare gli eventuali campi che contengono stringhe vuote oppure testi con un numero troppo piccolo di frasi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining import Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summarization.getInfo_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_finale = dataset_finale[dataset_finale['article'].apply(Summarization.count_sentences) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_finale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUM = Summarization(models = ['textrank-g', 'lexrank-s', 'lsa-s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = SUM.fit(dataset_finale, field = 'article', n_sentences = 3)\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.loc[0]['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.loc[0]['textrank-g_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.loc[0]['lexrank-s_summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modo più comune per valutare il contenuto informativo di un riassunto automatico è di confrontarlo con un riassunto scritto dall'uomo.\n",
    "\n",
    "Una delle metriche maggiormente usate a tale scopo è il ROUGE, che essenzialmente calcola le sovrapposizioni degli n-grammi tra i due riassunti messi a confronto. Un elevato grado di sovrapposizione dovrebbe indicare un alto livello di concetti condivisi tra i due riassunti.\n",
    "\n",
    "Questo tipo di metrica, tuttavia, non riesce a fornire nessun feedback sulla coerenza dell'abstract. \n",
    "\n",
    "Le metriche che abbiamo scelto sono: \n",
    "- Rouge-1 (one-grams);\n",
    "- Rouge-2 (bi-grams);\n",
    "- Rouge-L (Longest Common Subsequence).\n",
    "\n",
    "Per ognuna di esse, settando il parametro 'type_metric' uguale ad 'f', 'p' o 'r', si ha rispettivamente l'f-score, la precisione o la recall (di default è 'f')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary, df_scores = SUM.evaluate(df_summary, field_summary = 'reference_summary',\n",
    "                            metrics = ['rouge-1', 'rouge-2', 'rouge-l'], type_metric = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gli output di 'evaluate' sono:\n",
    "- un dizionario di dataframes, uno per ogni metrica scelta. Il singolo dataframe contiene gli scores calcolati per ogni modello;\n",
    "- un dataframe riassuntivo con le medie e le deviazioni standard degli scores per ogni metrica e ogni modello usati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['rouge-1_r_df'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe con la media e la deviazione standard degli scores per ogni metrica scelta:\\n\")\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo ora come estrarre le parole chiave da un testo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools.textMining import Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = Keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_res = kw.fit(dataset_finale, field = 'article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
